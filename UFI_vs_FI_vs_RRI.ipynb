{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMt2v/t5MRg73AQhmF3ExpA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomheston/A-Comparison-of-the-Relative-Risk-Index-with-Unit-Fragilty/blob/main/UFI_vs_FI_vs_RRI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "HzsC7eEGUNbs",
        "outputId": "daec403d-cc4a-475c-fa5f-7b5c953f0852"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BASE SETTINGS\n",
            "Total Cases Tested: 250\n",
            "Lowest number in 2x2 table: 50\n",
            "Highest number in 2x2 table: 150\n",
            "Lowest p-value: 0.000999\n",
            "Highest p-value: 0.05\n",
            "\n",
            "CORRELATIONS\n",
            "Correlation between FI and pv: -0.90364 avg: 5.28\n",
            "Correlation between UFI and pv: -0.88881 avg: 3.036\n",
            "Correlation between FQ1 and pv: -0.88755 avg: 0.015668408079152936\n",
            "Correlation between FQ2 and pv: -0.87791 avg: 0.009008227868135887\n",
            "Correlation between RRI and pv: -0.83787 avg: 11.668886175350364\n",
            "Correlation between pRRI and pv: -0.76455 avg: 0.034809533797610086\n",
            "------\n",
            "Correlations are significantly different\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_232bc077-5314-413d-a01c-b82285ab98a3\", \"2x2_tables.csv\", 63785)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Thomas F. Heston\n",
        "# GNU GPL v3.0\n",
        "# I am an academic, please give me a citation if you use this.\n",
        "# https://faculty.washington.edu/theston\n",
        "\n",
        "# Importing essential libraries for data handling and statistical analysis\n",
        "import pandas as pd\n",
        "from scipy.stats import fisher_exact, pearsonr\n",
        "from scipy.stats import chi2_contingency\n",
        "from scipy.stats import norm\n",
        "import numpy as np\n",
        "\n",
        "# set variables\n",
        "lowran = 50 # lowest number in the 2x2 table\n",
        "highestran = 150 # highest number in 2x2 table\n",
        "toppv=0.05 # highest p-value\n",
        "lowpv=0.000999 # lowest p-value\n",
        "cases = 1000 # how many cases to run\n",
        "\n",
        "# Function to generate data and compute p-values\n",
        "def generate_data_and_pvalues(rows=cases):\n",
        "    data = []\n",
        "    # start loop\n",
        "    while len(data) < rows:\n",
        "        highran = np.random.randint(lowran+1, highestran)\n",
        "        ao, bo, co, do = [int(x) for x in np.random.randint(lowran, highran, 4)]\n",
        "        zero_found = False  # Add this flag at the beginning of the loop\n",
        "\n",
        "        # we will use chi2 or fishers exact test to calculate p-values\n",
        "        #_, pv, _, _ = chi2_contingency([[ao, bo], [co, do]],correction=True)\n",
        "        _, pv = fisher_exact([[ao, bo], [co, do]])\n",
        "\n",
        "        #\n",
        "        # For this program, the UFI/FI is calculated only pv < 0.05\n",
        "        # UFI: marginal totals are all kept equal.\n",
        "        # FI: marginal totals are not kept equal.\n",
        "        # For both: if p<0.05 then add to smallest cell otherwise subtract\n",
        "        # from largest cell.\n",
        "        #\n",
        "        if lowpv < pv < toppv:\n",
        "            #\n",
        "            # A weakness of the UFI and FI is the confusion over which cell\n",
        "            # to modify if more than one cell = min or max, so to simplify\n",
        "            # this program we will only analyze cells with nonequal values.\n",
        "            #\n",
        "            if ao == bo or ao == co or ao == do or bo == co or bo == do or co == do:\n",
        "              #break\n",
        "              continue\n",
        "            #\n",
        "            smallest = min(ao, bo, co, do)\n",
        "            #a1, b1, c1, d1 = ao, bo, co, do\n",
        "\n",
        "            # Add retry logic\n",
        "            retry_count = 0\n",
        "            max_retries = 100\n",
        "\n",
        "            # calculate the FI\n",
        "            fi = 1\n",
        "            pv1 = 0\n",
        "            max_iter = 100  # or some reasonable limit\n",
        "            count = 0\n",
        "            while pv1 < toppv and count < max_iter and retry_count < max_retries:\n",
        "                if smallest == ao:\n",
        "                    a1, b1, c1, d1 = ao+fi, bo-fi, co, do\n",
        "                elif smallest == bo:\n",
        "                    a1, b1, c1, d1 = ao-fi, bo+fi, co, do\n",
        "                elif smallest == co:\n",
        "                    a1, b1, c1, d1 = ao, bo, co+fi, do-fi\n",
        "                elif smallest == do:\n",
        "                    a1, b1, c1, d1 = ao, bo, co-fi, do+fi\n",
        "                #\n",
        "                # if the smallest cell goes to zero then UFI/FI calculations\n",
        "                # break, so throw out these cases\n",
        "                if any(val == 0 for val in [a1, b1, c1, d1]):\n",
        "                    zero_found = True  # Set the flag to True if zero found\n",
        "                    #break\n",
        "                    retry_count += 1\n",
        "                    if retry_count > max_retries:\n",
        "                        continue\n",
        "                    smallest = min(ao, bo, co, do)\n",
        "                    continue\n",
        "                # calculate change in p-value (pv1)\n",
        "                #_, pv1, _, _ = chi2_contingency([[a1, b1], [c1, d1]], correction=True)\n",
        "                _, pv1 = fisher_exact([[a1, b1], [c1, d1]]) # pv= the p-value\n",
        "                #\n",
        "                if pv1 < toppv:\n",
        "                    fi += 1\n",
        "                count += 1\n",
        "                retry_count += 1\n",
        "\n",
        "            # Reset retry count\n",
        "            retry_count = 0\n",
        "\n",
        "            ufi=1\n",
        "            pv2 = 0\n",
        "            max_iter = 100  # or some reasonable limit\n",
        "            count = 0\n",
        "            while pv2 < toppv and count < max_iter and retry_count < max_retries:\n",
        "                if smallest in (ao, do):\n",
        "                    a2, b2, c2, d2 = ao+ufi, bo-ufi, co-ufi, do+ufi\n",
        "                elif smallest in (bo, co):\n",
        "                    a2, b2, c2, d2 = ao-ufi, bo+ufi, co+ufi, do-ufi\n",
        "                #\n",
        "                # if the smallest cell goes to zero then UFI/FI calculations\n",
        "                # break, so throw out these cases\n",
        "                if any(val == 0 for val in [a2, b2, c2, d2]):\n",
        "                    zero_found = True  # Set the flag to True if zero found\n",
        "                    #break\n",
        "                    retry_count += 1\n",
        "                    if retry_count > max_retries:\n",
        "                        continue\n",
        "                    smallest = min(ao, bo, co, do)\n",
        "                    continue\n",
        "                # calculate change in p-value (pv1)\n",
        "                #_, pv2, _, _ = chi2_contingency([[a2, b2], [c2, d2]], correction=True)\n",
        "                _, pv2 = fisher_exact([[a2, b2], [c2, d2]]) # pv= the p-value\n",
        "                #\n",
        "                if pv2 < toppv:\n",
        "                    ufi += 1\n",
        "                count += 1\n",
        "                retry_count += 1\n",
        "\n",
        "            if zero_found:  # Check the flag after the inner loop\n",
        "              continue  # Continue the outer loop if zero found\n",
        "\n",
        "            # RRI calculations\n",
        "            ppv1 = ao / (ao + bo)\n",
        "            ppv2 = co / (co + do)\n",
        "            inc_ppv = 1\n",
        "            ao2, bo2, co2, do2 = ao, bo, co, do\n",
        "            total = ao + bo + co + do\n",
        "            FQ1 = fi / total\n",
        "            FQ2 = ufi / total\n",
        "            RRI = abs((bo*co-ao*do)/(ao+bo+co+do)) # exact RR index\n",
        "            if ppv1>ppv2:\n",
        "              ppv3a=(ao2-RRI)/(ao2+bo2)\n",
        "              ppv3b=(co2+RRI)/(co2+do2)\n",
        "            elif ppv1<ppv2:\n",
        "              ppv3a=(ao2+RRI)/(ao2+bo2)\n",
        "              ppv3b=(co2-RRI)/(co2+do2)\n",
        "            pRRI = RRI/(ao + bo + co + do) # the average percent change in ao, bo, co and do to get them to a RR of 1.\n",
        "            data.append([ao, bo, co, do, pv, a1, b1, c1, d1, pv1, fi, FQ1, a2, b2, c2, d2, pv2, ufi, FQ2, ao2, bo2, co2, do2, ppv1, ppv2, ppv3a, ppv3b, RRI, pRRI])\n",
        "\n",
        "    columns = ['ao', 'bo', 'co', 'do', 'pv', 'a1', 'b1', 'c1', 'd1', 'pv1', 'fi', 'FQ1', 'a2', 'b2', 'c2', 'd2', 'pv2', 'ufi', 'FQ2', 'ao2', 'bo2', 'co2', 'do2', 'ppv1', 'ppv2', 'ppv3a', 'ppv3b', 'RRI','pRRI']\n",
        "    df = pd.DataFrame(data, columns=columns)\n",
        "    df['size'] = df['ao'] + df['bo'] + df['co'] + df['do']\n",
        "    df['pv'] = df['pv'].round(7)\n",
        "    df['pv1'] = df['pv1'].round(7)\n",
        "\n",
        "    # Correlated with p-value\n",
        "    corr_fi_pv, p_value_fi_pv = [round(val, 5) for val in pearsonr(df['fi'], df['pv'])]\n",
        "    corr_FQ1_pv, p_value_FQ1_pv = [round(val, 5) for val in pearsonr(df['FQ1'], df['pv'])]\n",
        "    corr_ufi_pv, p_value_ufi_pv = [round(val, 5) for val in pearsonr(df['ufi'], df['pv'])]\n",
        "    corr_FQ2_pv, p_value_FQ2_pv = [round(val, 5) for val in pearsonr(df['FQ2'], df['pv'])]\n",
        "    corr_RRI_pv, p_value_RRI_pv = [round(val, 5) for val in pearsonr(df['RRI'], df['pv'])]\n",
        "    corr_pRRI_pv, p_value_pRRI_pv = [round(val, 5) for val in pearsonr(df['pRRI'], df['pv'])]\n",
        "\n",
        "    #corr_fi_RRI, p_value_fi_RRI = [round(val, 5) for val in pearsonr(df['fi'], df['RRI'])]\n",
        "    #corr_FQ1_RRI, p_value_FQ1_RRI = [round(val, 5) for val in pearsonr(df['FQ1'], df['RRI'])]\n",
        "    #corr_ufi_RRI, p_value_ufi_RRI = [round(val, 5) for val in pearsonr(df['ufi'], df['RRI'])]\n",
        "    #corr_FQ2_RRI, p_value_FQ2_RRI = [round(val, 5) for val in pearsonr(df['FQ2'], df['RRI'])]\n",
        "\n",
        "    #corr_fi_pRRI, p_value_fi_pRRI = [round(val, 5) for val in pearsonr(df['fi'], df['pRRI'])]\n",
        "    #corr_FQ1_pRRI, p_value_FQ1_pRRI = [round(val, 5) for val in pearsonr(df['FQ1'], df['pRRI'])]\n",
        "    #corr_ufi_pRRI, p_value_ufi_pRRI = [round(val, 5) for val in pearsonr(df['ufi'], df['pRRI'])]\n",
        "    #corr_FQ2_pRRI, p_value_FQ2_pRRI = [round(val, 5) for val in pearsonr(df['FQ2'], df['pRRI'])]\n",
        "\n",
        "\n",
        "    # Calculate the averages\n",
        "    avgfi = df['fi'].mean()\n",
        "    avgufi = df['ufi'].mean()\n",
        "    avgFQ1 = df['FQ1'].mean()\n",
        "    avgFQ2 = df['FQ2'].mean()\n",
        "    avgRRI = df['RRI'].mean()\n",
        "    avgpRRI = df['pRRI'].mean()\n",
        "\n",
        "    # Print out base settings\n",
        "    print(\"BASE SETTINGS\")\n",
        "    print(\"Total Cases Tested:\", cases)\n",
        "    print(\"Lowest number in 2x2 table:\", lowran)\n",
        "    print(\"Highest number in 2x2 table:\", highestran)\n",
        "    print(\"Lowest p-value:\", lowpv)\n",
        "    print(\"Highest p-value:\", toppv)\n",
        "    print()\n",
        "\n",
        "    # Print out correlation results with p-values\n",
        "    print(\"CORRELATIONS\")\n",
        "    print(\"Correlation between FI and pv:\", corr_fi_pv, \"avg:\", avgfi)\n",
        "    print(\"Correlation between UFI and pv:\", corr_ufi_pv, \"avg:\", avgufi)\n",
        "    print(\"Correlation between FQ1 and pv:\", corr_FQ1_pv, \"avg:\", avgFQ1)\n",
        "    print(\"Correlation between FQ2 and pv:\", corr_FQ2_pv, \"avg:\", avgFQ2)\n",
        "    print(\"Correlation between RRI and pv:\", corr_RRI_pv, \"avg:\", avgRRI)\n",
        "    print(\"Correlation between pRRI and pv:\", corr_pRRI_pv, \"avg:\", avgpRRI)\n",
        "    print(\"------\")\n",
        "    # Correlation coefficients\n",
        "    r1 = corr_fi_pv\n",
        "    r2 = corr_pRRI_pv\n",
        "    # Sample sizes\n",
        "    n1 = len(df['fi'])\n",
        "    n2 = len(df['FQ1'])\n",
        "    # Fisher's Z transform\n",
        "    z1 = 0.5*np.log((1+r1)/(1-r1))\n",
        "    z2 = 0.5*np.log((1+r2)/(1-r2))\n",
        "    # Standard errors\n",
        "    se1 = 1/np.sqrt(n1-3)\n",
        "    se2 = 1/np.sqrt(n2-3)\n",
        "    # Z-statistic\n",
        "    z = (z1 - z2) / np.sqrt(se1**2 + se2**2)\n",
        "    # p-value\n",
        "    p = 2*norm.cdf(-abs(z))\n",
        "    # Interpret\n",
        "    alpha = 0.05\n",
        "    if p < alpha:\n",
        "      print(\"Correlations are significantly different\")\n",
        "    else:\n",
        "      print(\"Correlations are not significantly different\")\n",
        "\n",
        "    #print(\"Correlation between FI and RRI:\", corr_fi_RRI)\n",
        "    #print(\"Correlation between UFI and RRI:\", corr_ufi_RRI)\n",
        "    #print(\"Correlation between FQ1 and RRI:\", corr_FQ1_RRI)\n",
        "    #print(\"Correlation between FQ2 and RRI:\", corr_FQ2_RRI)\n",
        "    #print(\"------\")\n",
        "    #print(\"Correlation between FI and pRRI:\", corr_fi_pRRI)\n",
        "    #print(\"Correlation between UFI and pRRI:\", corr_ufi_pRRI)\n",
        "    #print(\"Correlation between FQ1 and pRRI:\", corr_FQ1_pRRI)\n",
        "    #print(\"Correlation between FQ2 and pRRI:\", corr_FQ2_pRRI)\n",
        "    #print()\n",
        "\n",
        "    return df\n",
        "\n",
        "# Generate the DataFrame\n",
        "df = generate_data_and_pvalues()\n",
        "\n",
        "# Print the DataFrame to a file (optional)\n",
        "# and Export from Colab (optional)\n",
        "df.to_csv('2x2_tables.csv', index=False)\n",
        "from google.colab import files\n",
        "files.download('2x2_tables.csv')\n"
      ]
    }
  ]
}